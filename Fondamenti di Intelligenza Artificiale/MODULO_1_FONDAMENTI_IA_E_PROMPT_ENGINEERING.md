# ğŸ“˜ MODULO 1
# Fondamenti di Intelligenza Artificiale e Prompt Engineering
## Corso ITS - Intelligenza Artificiale e Programmazione Assistita 2025
### Durata: 3 ore | Livello: Base-Intermedio

---

## ğŸ“‘ Indice del Modulo

1. [Introduzione e Obiettivi](#1-introduzione-e-obiettivi)
2. [Fondamenti di Intelligenza Artificiale](#2-fondamenti-di-intelligenza-artificiale)
3. [Large Language Models (LLM)](#3-large-language-models-llm)
4. [Limiti, Rischi e Uso Responsabile](#4-limiti-rischi-e-uso-responsabile)
5. [Prompt Engineering Professionale](#5-prompt-engineering-professionale)
6. [Framework e Metodologie](#6-framework-e-metodologie)
7. [Applicazioni in Ambito ITS](#7-applicazioni-in-ambito-its)
8. [Esercitazioni Pratiche](#8-esercitazioni-pratiche)

---

## 1. Introduzione e Obiettivi

### 1.1 Benvenuti al Corso 2025

Benvenuti! Questo corso vi insegnerÃ  a utilizzare l'**Intelligenza Artificiale come strumento professionale** per la programmazione, con focus particolare su sistemi embedded e applicazioni ITS (Istituto Tecnico Superiore).

**PerchÃ© questo corso Ã¨ importante per voi?**

Nel 2025, l'IA non Ã¨ piÃ¹ fantascienza o una tecnologia per pochi esperti. Ãˆ diventata uno **strumento di lavoro quotidiano** per programmatori, ingegneri e tecnici. Immaginate di avere un collega esperto sempre disponibile 24/7, che puÃ²:
- Scrivere codice al vostro posto
- Spiegare concetti complessi in modo semplice
- Trovare bug nel vostro codice
- Suggerire soluzioni a problemi tecnici

Ma attenzione: come ogni strumento potente, l'IA va usata **con intelligenza**. Non Ã¨ magia, ha limiti precisi, e puÃ² sbagliare. Questo corso vi insegnerÃ  **quando, come e perchÃ©** usare l'IA, e soprattutto **come riconoscere quando sbaglia**.

**NovitÃ  2025:**
- **Claude 3.5 Sonnet**: il migliore per seguire istruzioni precise
- **GPT-4 Turbo**: eccellente per codice e ragionamento complesso
- **Gemini 1.5 Pro**: puÃ² "leggere" documenti lunghissimi (2 milioni di parole!)
- **GitHub Copilot**: scrive codice mentre digitate nell'IDE
- **TinyML**: intelligenza artificiale che gira su Arduino!

### 1.2 Obiettivi di Apprendimento

Al termine di questo modulo (3 ore) sarai in grado di:

âœ… **Comprendere** cos'Ã¨ l'IA e come funzionano gli LLM moderni
   â†’ Saprai spiegare a un amico cosa fa ChatGPT "sotto il cofano"

âœ… **Riconoscere** limiti, bias e allucinazioni
   â†’ Non ti farai ingannare quando l'IA inventa fatti falsi

âœ… **Formulare** prompt tecnici efficaci
   â†’ Otterrai codice utilizzabile al primo colpo invece di perdere ore

âœ… **Applicare** framework professionali (CLEAR, Chain-of-Thought)
   â†’ Userai tecniche da professionista, non da principiante

âœ… **Valutare criticamente** output generati da IA
   â†’ Saprai dire se un codice Ã¨ buono o pericoloso

âœ… **Integrare** IA nel workflow di sviluppo
   â†’ L'IA diventerÃ  parte naturale del tuo lavoro

### 1.3 Strumenti 2025

**Cosa vi serve per iniziare?**

Niente di costoso! La maggior parte degli strumenti sono gratuiti o gratis per studenti.

**LLM Raccomandati (almeno 1 obbligatorio):**

```
GRATUITI AL 100%:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ChatGPT 3.5 (OpenAI)                   â”‚
â”‚ â”œâ”€ Gratis forever                      â”‚
â”‚ â”œâ”€ Molto buono per iniziare            â”‚
â”‚ â””â”€ Limite: qualitÃ  inferiore a GPT-4   â”‚
â”‚                                        â”‚
â”‚ Claude 3.5 Sonnet (Anthropic)          â”‚
â”‚ â”œâ”€ Gratis con limiti                   â”‚
â”‚ â”œâ”€ Eccellente per istruzioni precise   â”‚
â”‚ â””â”€ Limite: ~50 messaggi/giorno free    â”‚
â”‚                                        â”‚
â”‚ Gemini 1.5 (Google)                    â”‚
â”‚ â”œâ”€ Gratis con account Google           â”‚
â”‚ â”œâ”€ Context window ENORME               â”‚
â”‚ â””â”€ Limite: piÃ¹ lento dei concorrenti   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STUDENTI (GRATIS CON VERIFICA):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GitHub Copilot                         â”‚
â”‚ â”œâ”€ Gratis con GitHub Student Pack      â”‚
â”‚ â”œâ”€ Si integra nell'IDE (VSCode, etc)   â”‚
â”‚ â”œâ”€ Scrive codice mentre digiti         â”‚
â”‚ â””â”€ FORTEMENTE RACCOMANDATO              â”‚
â”‚                                        â”‚
â”‚ ChatGPT Plus                           â”‚
â”‚ â”œâ”€ Normalmente $20/mese                â”‚
â”‚ â”œâ”€ Gratis per studenti verificati      â”‚
â”‚ â””â”€ Accesso a GPT-4 (migliore qualitÃ )  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PRO (A PAGAMENTO - OPZIONALE):
- ChatGPT Plus: $20/mese
- Claude Pro: $20/mese
- Cursor IDE: $20/mese (editor con IA integrata)
```

**Come ottenere GitHub Student Pack (IMPORTANTE!):**

Il GitHub Student Pack Ã¨ un regalo incredibile per studenti: oltre 100 tool professionali gratis, incluso GitHub Copilot che normalmente costa $10/mese!

```
PASSI:
1. Vai su: https://education.github.com/pack
2. Clicca "Get Student Benefits"
3. Verifica identitÃ  studente con:
   â”œâ”€ Email istituzionale ITS (@its...)
   â”œâ”€ Foto documento studente
   â””â”€ Prova iscrizione
4. Attendi approvazione (1-7 giorni)
5. Attiva Copilot su VSCode

COSA OTTIENI:
âœ“ GitHub Copilot (valore $120/anno)
âœ“ Domini .me gratis
âœ“ Cloud credits AWS/Azure
âœ“ + altri 100+ tool professionali
```

**Configurazione Ambiente Base:**

```bash
# 1. EDITOR RACCOMANDATO
Visual Studio Code (gratuito)
â†’ https://code.visualstudio.com/

# 2. ESTENSIONI VSCODE ESSENZIALI
- GitHub Copilot (se hai Student Pack)
- C/C++ (Microsoft)
- Arduino (Microsoft)
- ChatGPT (extension ufficiale)

# 3. ACCOUNT DA CREARE
â–¡ Account OpenAI (ChatGPT)
â–¡ Account Anthropic (Claude)
â–¡ Account Google (Gemini)
â–¡ GitHub account (per Student Pack)
```

---

## 2. Fondamenti di Intelligenza Artificiale

### 2.1 Cos'Ã¨ l'IA nel 2025

**Definizione Semplice:**

> **Intelligenza Artificiale**: programmi che imparano a fare cose intelligenti guardando esempi, invece di seguire istruzioni scritte da programmatori.

**Pensate alla differenza:**

**Programmazione Tradizionale:**
```python
# Il programmatore scrive OGNI regola
def Ã¨_spam(email):
    if "viagra" in email:
        return True
    if "gratis" in email and "vinci" in email:
        return True
    # ...devi scrivere 1000 regole...
    return False
```
â†’ Serve il programmatore per ogni nuova regola
â†’ Non si adatta a nuovi trucchi degli spammer

**Intelligenza Artificiale:**
```python
# L'IA impara DA SOLA dai dati
modello = train_spam_detector(
    esempi_spam=10000,     # email spam
    esempi_normali=10000   # email normali
)

# Ora riconosce spam MAI VISTO PRIMA
print(modello.Ã¨_spam("...nuova email..."))
```
â†’ Impara pattern complessi dai dati
â†’ Si adatta a nuovi tipi di spam

**Evoluzione Storica (Timeline per capire dove siamo):**

```
1950s: NASCITA
â”œâ”€ Test di Turing (1950)
â”œâ”€ "PuÃ² una macchina pensare?"
â””â”€ Solo teoria, nessun risultato pratico

1980s-1990s: INVERNO IA
â”œâ”€ Computer troppo lenti
â”œâ”€ Dati insufficienti
â””â”€ Poche applicazioni reali

2010s: RINASCITA
â”œâ”€ 2012: Deep Learning funziona (ImageNet)
â”œâ”€ GPU potenti + Big Data
â”œâ”€ Google, Facebook investono miliardi
â””â”€ Assistenti vocali (Siri, Alexa)

2020s: RIVOLUZIONE
â”œâ”€ 2022: ChatGPT (175 miliardi parametri!)
â”‚        â†’ 100 milioni utenti in 2 mesi
â”œâ”€ 2023: GPT-4 (multimodale: testo+immagini)
â”‚        â†’ Supera esami professionali
â”œâ”€ 2024: Claude 3.5, Gemini 1.5 Pro
â”‚        â†’ Context window 2 milioni token
â””â”€ 2025: IA in OGNI strumento
         â†’ IDE, browser, sistemi operativi
```

**PerchÃ© PROPRIO ORA Ã¨ il momento della rivoluzione?**

Tre fattori si sono allineati:

1. **DATI**: Internet ha creato oceani di testo/immagini/video
2. **COMPUTING**: GPU moderne 1000x piÃ¹ potenti di 10 anni fa
3. **ALGORITMI**: Transformer (2017) ha sbloccato tutto

Ãˆ come avere benzina (dati) + motore (GPU) + chiave per accenderlo (algoritmi).

### 2.2 Categorie IA Essenziali

L'IA Ã¨ un termine generico. Sotto questo ombrello ci sono TANTI tipi diversi di tecnologie. Ecco le principali che dovete conoscere:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    CATEGORIE IA (Focus 2025)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚ 1. MACHINE LEARNING (ML)                â”‚
â”‚    Apprendimento da dati con algoritmi  â”‚
â”‚    statistici                           â”‚
â”‚    â”‚                                    â”‚
â”‚    â”œâ”€ Supervised Learning               â”‚
â”‚    â”‚  (impara da esempi etichettati)    â”‚
â”‚    â”‚  Es: Spam detector, diagnosi       â”‚
â”‚    â”‚                                    â”‚
â”‚    â”œâ”€ Unsupervised Learning             â”‚
â”‚    â”‚  (trova pattern da solo)           â”‚
â”‚    â”‚  Es: Clustering clienti            â”‚
â”‚    â”‚                                    â”‚
â”‚    â””â”€ Reinforcement Learning            â”‚
â”‚       (impara per tentativi/errori)     â”‚
â”‚       Es: AlphaGo, robot                â”‚
â”‚                                         â”‚
â”‚ 2. DEEP LEARNING                        â”‚
â”‚    Reti neurali "profonde" (tanti       â”‚
â”‚    layer) che imparano automaticamente  â”‚
â”‚    â”‚                                    â”‚
â”‚    â”œâ”€ Computer Vision                   â”‚
â”‚    â”‚  (riconoscimento immagini)         â”‚
â”‚    â”‚  Es: Face ID, auto autonome        â”‚
â”‚    â”‚                                    â”‚
â”‚    â”œâ”€ NLP (Natural Language)            â”‚
â”‚    â”‚  (comprensione linguaggio)         â”‚
â”‚    â”‚  Es: ChatGPT, traduttori           â”‚
â”‚    â”‚                                    â”‚
â”‚    â””â”€ Speech Recognition                â”‚
â”‚       (riconoscimento vocale)           â”‚
â”‚       Es: Alexa, Siri                   â”‚
â”‚                                         â”‚
â”‚ 3. IA GENERATIVA â­ (FOCUS 2025)       â”‚
â”‚    IA che CREA contenuti nuovi          â”‚
â”‚    â”‚                                    â”‚
â”‚    â”œâ”€ LLM (Large Language Models)       â”‚
â”‚    â”‚  Generano TESTO e CODICE           â”‚
â”‚    â”‚  Es: ChatGPT, Claude, Gemini       â”‚
â”‚    â”‚  â†’ QUESTO Ãˆ IL NOSTRO FOCUS!       â”‚
â”‚    â”‚                                    â”‚
â”‚    â”œâ”€ Image Generation                  â”‚
â”‚    â”‚  Generano IMMAGINI                 â”‚
â”‚    â”‚  Es: DALL-E 3, Midjourney, Stable  â”‚
â”‚    â”‚                                    â”‚
â”‚    â””â”€ Multi-Modal                       â”‚
â”‚       Capiscono/generano testo+immagini â”‚
â”‚       Es: GPT-4V, Gemini 1.5           â”‚
â”‚                                         â”‚
â”‚ 4. EDGE AI / TinyML â­                 â”‚
â”‚    IA che gira su microcontrollori!     â”‚
â”‚    Es: Keyword spotting su Arduino      â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Spiegazione Categorie con Esempi Pratici:**

#### **1. Machine Learning (ML)**

Il ML Ã¨ la base di tutto. L'idea: invece di programmare regole, dai esempi e l'algoritmo impara le regole da solo.

**Esempio Supervised Learning:**
```
PROBLEMA: Riconoscere se un'email Ã¨ spam

DATI TRAINING:
Email 1: "Vinci iPhone gratis!" â†’ SPAM âœ“
Email 2: "Riunione domani ore 10" â†’ OK âœ“
Email 3: "Viagra sconto 90%" â†’ SPAM âœ“
...10.000 esempi...

ALGORITMO IMPARA:
- Parole spam: "gratis", "vinci", "viagra"
- Pattern spam: molti CAPS, link strani
- Mittenti spam: domini sospetti

RISULTATO:
Input: nuova email mai vista
Output: SPAM (85% sicuro) o OK (98% sicuro)
```

**Esempio Unsupervised Learning:**
```
PROBLEMA: Raggruppa clienti simili

DATI:
Cliente A: Compra [pasta, pomodori, basilico]
Cliente B: Compra [birra, patatine, pizza]
Cliente C: Compra [pasta, olio, aglio]
...

ALGORITMO TROVA GRUPPI DA SOLO:
Cluster 1: "Cucinatori italiani" (A, C)
Cluster 2: "Party people" (B)

USO: Marketing mirato per ogni cluster
```

#### **2. Deep Learning**

Deep Learning = Machine Learning con reti neurali molto "profonde" (tanti layer). PuÃ² imparare concetti sempre piÃ¹ astratti.

**Analogia:**
```
Layer 1: Rileva linee/bordi in immagine
   â†“
Layer 2: Combina linee in forme (occhi, naso)
   â†“
Layer 3: Combina forme in oggetti (volto)
   â†“
Layer 4: Riconosce CHI Ã¨ la persona
```

**Applicazione ITS:**
```
COMPUTER VISION su produzione:
Camera â†’ Deep Learning Model â†’ Difetto rilevato!

Es: Controllo qualitÃ  PCB (circuit board)
- Input: Foto PCB
- Model: CNN (Convolutional Neural Network)
- Output: "Saldatura difettosa sulla resistenza R7"
- Accuratezza: >99.5%
```

#### **3. IA Generativa (FOCUS CORSO)**

Questa Ã¨ la rivoluzione 2022-2025. IA che non solo riconosce, ma **CREA** contenuti nuovi.

**Large Language Models (LLM):**

Immaginate un modello che ha "letto" quasi tutto internet:
- Wikipedia completa
- Milioni di libri
- Codice GitHub (miliardi di righe)
- Forum, blog, paper scientifici

Ora puÃ²:
- Rispondere a domande
- Scrivere articoli
- **Generare codice** â† QUESTO CI INTERESSA!
- Tradurre linguaggi
- Riassumere documenti

**Come Ã¨ possibile?**

Il modello ha imparato **pattern statistici** del linguaggio. Non "capisce" veramente, ma Ã¨ bravissimo a prevedere "quale parola viene dopo".

```
Input: "La capitale d'Italia Ã¨"
Model pensa:
  "Roma" â†’ 92% probabilitÃ  âœ“
  "Milano" â†’ 3%
  "Parigi" â†’ 0.001%
Output: "Roma"
```

Ma con miliardi di parametri e addestramento sofisticato, questi pattern diventano sorprendentemente intelligenti!

#### **4. Edge AI / TinyML**

Questa Ã¨ la frontiera per embedded! IA che gira su microcontrollori con pochi KB di RAM.

**Caso d'uso reale:**
```
KEYWORD SPOTTING su Arduino Nano 33 BLE:

Hardware:
- MCU: ARM Cortex-M4 (64 MHz)
- RAM: 256 KB
- Flash: 1 MB

Model:
- Tipo: CNN
- Dimensione: 30 KB (!)
- Accuratezza: 94%

FunzionalitÃ :
Microfono â†’ Model â†’ Riconosce "Arduino"
                  â†’ Attiva azione

Consumi:
- Idle: 50 ÂµA
- Active: 8 mA
- Batteria dura MESI
```

**PerchÃ© Ã¨ importante?**
- Privacy: dati restano locali
- Latenza: risposta istantanea
- AffidabilitÃ : no dipendenza cloud
- Costo: no connettivitÃ  necessaria

### 2.3 IA vs Algoritmi Tradizionali

**Quando usare cosa?**

Questa Ã¨ una domanda FONDAMENTALE per ingegneri. Non tutto va risolto con IA!

| Scenario | Algoritmo Classico | IA/ML | Vincitore |
|----------|-------------------|-------|-----------|
| **Calcolare IVA su vendita** | `prezzo * 0.22` | Rete neurale addestrata su esempi | âŒ Algoritmo! (IA Ã¨ overkill) |
| **Classificare email spam** | Regole if/then manuali | Modello ML addestrato | âœ… IA! (troppi pattern) |
| **Riconoscimento vocale** | Pattern matching acustico | Deep Learning CNN/RNN | âœ… IA! (impossibile altrimenti) |
| **PID controller** | Formula PID classica | Reinforcement Learning | âš–ï¸ Dipende! (PID ok per casi semplici) |
| **Generare codice da descrizione** | Template + regex | LLM (GPT-4) | âœ… IA! (unica opzione) |
| **Ordinare array** | Quicksort | Neural Sort | âŒ Algoritmo! (piÃ¹ veloce, deterministico) |
| **Predire guasto motore** | Soglie fisse | ML + sensori | âœ… IA! (pattern complessi) |

**Regole Pratiche 2025:**

```
USA ALGORITMI CLASSICI quando:
âœ“ Le regole sono chiare e stabili
  Es: calcolo IVA non cambierÃ  domani

âœ“ Precisione matematica Ã¨ CRITICA
  Es: sistemi safety-critical (avionica)

âœ“ SpiegabilitÃ  Ã¨ obbligatoria
  Es: "perchÃ© il controllo ha fatto X?"

âœ“ Dati insufficienti
  Es: 10 esempi non bastano per ML

âœ“ Risorse limitate
  Es: Arduino Uno (2KB RAM!)

USA IA/ML quando:
âœ“ Pattern troppo complessi per regole
  Es: "questa immagine contiene un gatto?"

âœ“ Hai TANTI dati
  Es: 10.000+ esempi etichettati

âœ“ Task creativi/generativi
  Es: scrivere codice, testi, immagini

âœ“ Ambiente cambia nel tempo
  Es: nuovi tipi di spam ogni giorno

âœ“ Approssimazione accettabile
  Es: 95% accuratezza Ã¨ ok
```

**Esempio Reale ITS: Sistema Rilevamento Difetti**

```
SCENARIO: Controllo qualitÃ  saldature PCB

APPROCCIO CLASSICO:
```c
bool saldatura_ok(Image img, Point p) {
    // Controlla dimensione
    if (area(p) < MIN_AREA) return false;
    if (area(p) > MAX_AREA) return false;

    // Controlla colore
    if (brightness(p) < MIN_BRIGHT) return false;

    // Controlla forma
    if (circolaritÃ (p) < 0.8) return false;

    return true;
}
```
**Problemi:**
- Devi definire TUTTE le regole manualmente
- Non funziona su nuovi tipi di difetti
- Falsi positivi/negativi alti

**APPROCCIO IA:**
```python
# Training
model = train_cnn(
    immagini_ok = 5000,
    immagini_difetto = 5000
)

# Inference
difetto = model.predict(nuova_immagine)
# â†’ 98.2% accuratezza!
```
**Vantaggi:**
- Impara automaticamente i pattern
- Si adatta a nuovi difetti con re-training
- Accuratezza superiore

**Conclusione per questo caso: IA vince!**

---

## 3. Large Language Models (LLM)

### 3.1 Cosa Sono gli LLM

Gli **LLM (Large Language Models)** sono il cuore di ChatGPT, Claude, e Gemini. Sono quello che useremo per programmare con l'IA.

**Definizione Semplice:**

> **LLM**: Un programma di intelligenza artificiale addestrato su MILIARDI di pagine di testo da internet, libri e codice. PuÃ² capire cosa scrivi e generare risposte sensate, incluso codice funzionante.

**Ma come funziona veramente?**

Pensate a un gioco dove dovete indovinare la parola successiva:

```
"Il gatto dorme sul ___"

Voi probabilmente direste:
- "divano" (molto probabile)
- "letto" (probabile)
- "tetto" (possibile)
- "aeroplano" (wtf? no!)
```

Un LLM fa la STESSA cosa, ma:
1. Ha visto MILIARDI di frasi simili
2. Ha imparato pattern statistici
3. PuÃ² farlo per QUALSIASI contesto

**LLM Principali 2025 (Comparison):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GPT-4 Turbo (OpenAI)                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Parametri: ~1.7 trilioni (1,700,000,000,000!)         â”‚
â”‚ Context: 128,000 token (~100k parole, ~400 pagine)    â”‚
â”‚ Costo: $0.01 per 1k token input                       â”‚
â”‚                                                        â”‚
â”‚ âœ… PUNTI DI FORZA:                                     â”‚
â”‚   - Eccellente per codice                             â”‚
â”‚   - Ragionamento matematico                           â”‚
â”‚   - Multimodale (vede immagini!)                      â”‚
â”‚   - Function calling preciso                          â”‚
â”‚                                                        â”‚
â”‚ âŒ PUNTI DEBOLI:                                       â”‚
â”‚   - PiÃ¹ costoso dei concorrenti                       â”‚
â”‚   - A volte troppo verboso                            â”‚
â”‚   - Censura eccessiva su alcuni topic                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Claude 3.5 Sonnet (Anthropic)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Parametri: Non dichiarati (segreto!)                  â”‚
â”‚ Context: 200,000 token (~150k parole)                 â”‚
â”‚ Costo: $0.003 per 1k token (3x cheaper!)              â”‚
â”‚                                                        â”‚
â”‚ âœ… PUNTI DI FORZA:                                     â”‚
â”‚   - MIGLIORE per seguire istruzioni                   â”‚
â”‚   - Analisi codice accurata                           â”‚
â”‚   - Meno allucinazioni di GPT                         â”‚
â”‚   - Stile di scrittura naturale                       â”‚
â”‚                                                        â”‚
â”‚ âŒ PUNTI DEBOLI:                                       â”‚
â”‚   - Meno bravo su matematica complessa                â”‚
â”‚   - Meno conosciuto = meno esempi online              â”‚
â”‚   - Rate limits piÃ¹ stretti (free tier)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gemini 1.5 Pro (Google)                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Parametri: Non dichiarati                             â”‚
â”‚ Context: 2,000,000 token (!!!) = ~1 milione parole!   â”‚
â”‚ Costo: $0.00125 per 1k token (cheapest!)              â”‚
â”‚                                                        â”‚
â”‚ âœ… PUNTI DI FORZA:                                     â”‚
â”‚   - Context ENORME (puÃ² leggere interi libri)         â”‚
â”‚   - Gratis con limiti generosi                        â”‚
â”‚   - Multimodale avanzato                              â”‚
â”‚   - Integrazione Google Workspace                     â”‚
â”‚                                                        â”‚
â”‚ âŒ PUNTI DEBOLI:                                       â”‚
â”‚   - PiÃ¹ lento dei concorrenti                         â”‚
â”‚   - QualitÃ  codice inferiore a GPT-4                  â”‚
â”‚   - Meno adatto a task specifici                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Quale usare?**

```
Per CODICE COMPLESSO:
â†’ GPT-4 Turbo
  Esempio: "Implementa Red-Black Tree in C"

Per SEGUIRE ISTRUZIONI PRECISE:
â†’ Claude 3.5 Sonnet
  Esempio: "Genera sketch Arduino con ESATTAMENTE
            questi 15 requisiti..."

Per ANALIZZARE DOCUMENTI LUNGHI:
â†’ Gemini 1.5 Pro
  Esempio: "Leggi questo datasheet 500 pagine e
            trova i pin per I2C"

Per IMPARARE/SPERIMENTARE GRATIS:
â†’ ChatGPT 3.5 o Claude Free
  Funzionano benissimo per il 90% dei casi!
```

### 3.2 Come Funzionano (Spiegazione Semplificata)

**Il Viaggio di un Prompt (Step-by-Step):**

Quando scrivi "Scrivi funzione C per sommare array" e premi invio, cosa succede?

```
STEP 1: TOKENIZZAZIONE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Il tuo testo viene spezzato in "token"
(pezzi di parole)

Input: "Scrivi funzione C"
â†“
Token: ["Scr", "ivi", " funzione", " C"]

PerchÃ© non parole intere?
â†’ Gestisce meglio parole nuove/rare
â†’ Funziona su TUTTE le lingue
â†’ PiÃ¹ efficiente per il modello

Un token â‰ˆ 4 caratteri in italiano
"Ciao come stai?" = ~4 token
```

```
STEP 2: EMBEDDING
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Ogni token â†’ Vettore di numeri
(rappresentazione matematica)

"Scrivi" â†’ [0.2, -0.5, 0.8, ..., 0.3]
           (4096 numeri!)

Cosa rappresentano questi numeri?
â†’ SIGNIFICATO SEMANTICO

Token simili hanno vettori simili:
"Scrivi" â‰ˆ "Genera" â‰ˆ "Crea"
"C" â‰ˆ "C++" â‰ˆ "codice"

Questo permette al modello di "capire"
relazioni tra concetti!
```

```
STEP 3: ATTENTION MECHANISM
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Il cuore del Transformer!

Il modello "presta attenzione" a token
rilevanti per predire il prossimo

Esempio:
Input: "Scrivi funzione C per invertire stringa"

Quando genera codice, presta attenzione a:
- "funzione" â†’ genererÃ  `tipo nome()`
- "C" â†’ userÃ  sintassi C, non Python
- "invertire" â†’ algoritmo reverse
- "stringa" â†’ tipo `char*`

Ãˆ come sottolineare le parti importanti
di un testo mentre studi!
```

```
STEP 4: PREDIZIONE PROBABILISTICA
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Il modello genera UN token alla volta
scegliendo il piÃ¹ probabile

Dopo "Scrivi funzione C per sommare array",
il modello calcola:

Prossimo token:
"void" â†’ 45% prob
"int" â†’ 40% prob
"\n" â†’ 10% prob (inizia su nuova riga)
"float" â†’ 4% prob
"class" â†’ 0.001% (sbagliato, C non ha class!)

Sceglie: "int" (in questo caso)

Poi ripete:
"int" â†’ Prossimo token:
"sum" â†’ 30%
"add" â†’ 25%
"array" â†’ 20%
...
```

```
STEP 5: ITERAZIONE FINO A COMPLETAMENTO
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Ripete step 4 finchÃ©:
- Genera token di STOP
- Raggiunge limite token
- Tu fermi generazione

Genera cosÃ¬ 100, 1000, 10000 token...
e costruisce risposta completa!
```

**Esempio Concreto Completo:**

```
PROMPT:
"Scrivi funzione C che calcola fattoriale"

GENERAZIONE (semplificato):
Token 1: "int" (45% prob)
Token 2: " fattoriale" (52% prob)
Token 3: "(" (98% prob - deve aprire parentesi!)
Token 4: "int" (78% prob)
Token 5: " n" (65% prob - nome parametro comune)
Token 6: ")" (99% prob)
Token 7: " {" (99% prob)
Token 8: "\n" (95% prob - new line)
Token 9: "    if" (70% prob - case base ricorsione)
...continua...

RISULTATO:
int fattoriale(int n) {
    if (n <= 1) return 1;
    return n * fattoriale(n - 1);
}
```

**Ma come fa a "sapere" la formula del fattoriale?**

**Non "sa" nulla!** Ha solo visto MILIONI di esempi di codice durante training:

```
Training data (semplificato):
- Visto 10,000 implementazioni fattoriale su GitHub
- Visto spiegazioni su Wikipedia/StackOverflow
- Visto esami/esercizi di programmazione

Ha imparato il PATTERN:
"fattoriale" + "ricorsione" â†’
   if (n <= 1) return 1;
   return n * fattoriale(n-1);
```

Ãˆ come uno studente che ha fatto 10,000 esercizi: non "capisce" matematicamente, ma ha visto il pattern cosÃ¬ tante volte che lo riproduce perfettamente!

### 3.3 CapacitÃ  e Limiti

**âœ… Cosa Fanno BENISSIMO**

#### **1. Generazione Codice**

```
ECCELLENTI PER:

âœ“ Funzioni standard (sorting, searching, etc)
âœ“ Boilerplate code (setup Arduino, init struct)
âœ“ Implementazione algoritmi noti
âœ“ Conversione tra linguaggi
âœ“ Wrapper per API

ESEMPIO REALE:
Prompt: "Implementa merge sort in C"
â†’ Genera implementazione corretta 95% volte
â†’ Spesso piÃ¹ pulita di quella di studente medio!
```

#### **2. Debugging**

```
âœ“ Spiega errori compilatore in linguaggio semplice
âœ“ Trova bug evidenti (null pointer, off-by-one)
âœ“ Suggerisce fix
âœ“ Propone test case che fallirebbero

ESEMPIO:
Input: "error: invalid conversion from 'const char*' to 'char*'"
â†’ LLM spiega: "Stai passando stringa costante a
   funzione che si aspetta puntatore modificabile.
   Soluzione: cambia parametro in const char*"
```

#### **3. Documentazione**

```
âœ“ Genera commenti Doxygen
âœ“ Scrive README.md professionali
âœ“ Crea docstring Python
âœ“ Spiega codice complesso

ESEMPIO:
Input: [funzione complessa senza commenti]
Prompt: "Aggiungi commenti Doxygen"
â†’ Output: documentazione completa, parametri, return, esempi
```

#### **4. Refactoring**

```
âœ“ Migliora naming variabili
âœ“ Estrae funzioni da codice duplicato
âœ“ Semplifica logica complessa
âœ“ Applica design pattern

ESEMPIO:
Input: codice con 500 righe in un'unica funzione
Prompt: "Refactora in funzioni piÃ¹ piccole"
â†’ Output: 10 funzioni ben nominate, ognuna <50 righe
```

#### **5. Learning Assistant**

```
âœ“ Spiega concetti in modo semplice
âœ“ Genera esercizi personalizzati
âœ“ Confronta approcci diversi
âœ“ Risponde a "perchÃ©?" infinite volte senza irritarsi!

ESEMPIO STUDENTE:
"PerchÃ© usare malloc invece di array fisso?"
â†’ Spiegazione con pro/cons, esempi, casi d'uso
"Ok ma quando DEVO usare malloc?"
â†’ Scenari specifici con codice
"E se malloc fallisce?"
â†’ Error handling patterns
[...puoi continuare all'infinito...]
```

**âŒ Limiti CRITICI (IMPORTANTE!)**

#### **1. Allucinazioni**

```
PROBLEMA #1: Inventa fatti/funzioni inesistenti

ESEMPIO REALE (successo davvero!):
Prompt: "Copia stringa in C"
Output IA:
  char* copy = strdup(original);

PROBLEMA: strdup() NON Ã¨ standard C!
â†’ Non compila su embedded
â†’ Non compila con -std=c99
â†’ Ma SEMBRA corretto!

COME DIFENDERSI:
âœ“ Compila sempre il codice
âœ“ Leggi documentazione ufficiale
âœ“ Se non conosci una funzione, cercala!
âœ“ Usa -Wall -Wextra -Wpedantic
```

#### **2. Knowledge Cutoff**

```
PROBLEMA #2: Dati limitati a data di training

GPT-4: Training fino aprile 2023
â†’ Non conosce librerie/tool usciti dopo
â†’ Non conosce nuove versioni Arduino
â†’ Non sa eventi recenti

ESEMPIO:
"Usa nuova libreria XYZ del 2024"
â†’ "Non conosco questa libreria"
â†’ Potrebbe inventare API inesistente!

SOLUZIONE:
âœ“ Fornisci documentazione nel prompt
âœ“ Specifica versioni esatte
âœ“ Verifica online esistenza librerie
```

#### **3. No Vera Comprensione**

```
PROBLEMA #3: Pattern matching, non ragionamento

L'IA non "capisce" cosa fa il codice.
Riproduce pattern visti, come pappagallo intelligente.

ESEMPIO PROBLEMA:
Prompt: "Scrivi funzione che trova numero primo
         piÃ¹ grande di N"

Potrebbe generare:
bool isPrime(int n) { ... }  // âœ“ corretto
int nextPrime(int n) {
    for (int i = n+1; ; i++) {
        if (isPrime(i)) return i;
    }
}
// âŒ LOOP INFINITO se n molto grande!
// Non ha "capito" che serve limite

LEZIONE:
âœ“ Testa sempre edge cases
âœ“ Non fidarti ciecamente
âœ“ Verifica logica, non solo sintassi
```

#### **4. Matematica Complessa Fallisce**

```
PROBLEMA #4: Calcoli complessi inaffidabili

ESEMPIO:
"Qual Ã¨ 127 * 843?"

IA potrebbe dire: 107,061

Risposta corretta: 107,061 âœ“
Ma se chiedi: "E 127 * 844?"
Potrebbe dire: 107,188 âŒ (giusto: 107,188)

Piccolo errore! Ma su calcoli complessi peggiora.

SOLUZIONE:
âœ“ Non usare LLM per matematica precisa
âœ“ Usa calcolatrice/codice per calcoli
âœ“ LLM va bene per LOGICA, non aritmetica
```

#### **5. Sicurezza Non Garantita**

```
PROBLEMA #5: PuÃ² generare codice vulnerabile

ESEMPIO:
Prompt: "Leggi password da input"
Output potenziale:
  char password[20];
  scanf("%s", password);  // âŒ BUFFER OVERFLOW!

Ãˆ sintatticamente corretto ma PERICOLOSO!

COME DIFENDERSI:
âœ“ Code review sempre
âœ“ Static analysis (cppcheck)
âœ“ Fuzzing/testing
âœ“ Non usare in sistemi safety-critical
   senza validazione esperta
```

**TABELLA RIASSUNTIVA - Quando Fidarsi**

| Task | AffidabilitÃ  | Note |
|------|-------------|------|
| **Genera funzione semplice** | 90% | Verifica sempre compilazione |
| **Spiega errore compilatore** | 95% | Ottime spiegazioni |
| **Matematica semplice** | 70% | Meglio usare calcolatrice |
| **Matematica complessa** | 30% | âŒ Non affidabile |
| **Trova bug evidenti** | 85% | Buono ma non perfetto |
| **Trova bug sottili** | 40% | Serve umano esperto |
| **Genera documentazione** | 95% | Eccellente |
| **Code sicuro security-critical** | 50% | âŒ Serve review esperto |
| **Spiega concetti** | 90% | Ottimo teacher |
| **Genera test case** | 80% | Buono, ma aggiungi edge cases tu |

---

## 4. Limiti, Rischi e Uso Responsabile

### 4.1 Allucinazioni - Il Problema #1

**Cos'Ã¨ un'allucinazione?**

> **Allucinazione IA**: Quando il modello genera informazioni che sembrano vere e plausibili, ma sono completamente inventate.

Ãˆ come uno studente che invece di dire "non lo so", inventa una risposta che SEMBRA giusta ma Ã¨ falsa.

**PerchÃ© succede?**

L'LLM Ã¨ addestrato a generare testo che "suona bene", non necessariamente testo VERO. Se non sa qualcosa, potrebbe inventare per completare il pattern!

**Esempi Reali di Allucinazioni:**

#### **Esempio 1: Funzioni Inesistenti (MOLTO COMUNE)**

```c
// âŒ ALLUCINAZIONE TIPICA

Prompt: "Duplica stringa in C"

Output IA:
char *duplicate = strdup(original);

PROBLEMA:
strdup() NON esiste in C standard!
- Ãˆ una estensione POSIX
- Non compila con -std=c99
- Non funziona su molti embedded
- Ma SEMBRA perfetto!

âœ… VERSIONE CORRETTA:
char *duplicate = malloc(strlen(original) + 1);
if (duplicate != NULL) {
    strcpy(duplicate, original);
}
```

#### **Esempio 2: Librerie Inventate**

```cpp
// âŒ ALLUCINAZIONE

Prompt: "Usa sensore XYZ con Arduino"

Output IA:
#include <XYZ_Sensor.h>  // âŒ NON ESISTE!

XYZ_Sensor sensor(A0);
sensor.begin();
float value = sensor.read();

PROBLEMA:
- Libreria inventata
- Metodi plausibili ma falsi
- Compila solo se NON provi davvero

COME RILEVARE:
âœ“ Cerca libreria su Library Manager Arduino
âœ“ Controlla su GitHub
âœ“ Verifica documentazione ufficiale
```

#### **Esempio 3: "Fatti" Inventati**

```
Prompt: "Quanti studenti ITS in Italia 2024?"

Output possibile:
"Ci sono 47.532 studenti iscritti a ITS in Italia
nel 2024, con un aumento del 12.3% rispetto al 2023."

PROBLEMA:
- Numeri TROPPO specifici (sospetto!)
- Nessuna fonte citata
- Potrebbe essere inventato

COME VERIFICARE:
âœ“ Chiedi: "Qual Ã¨ la fonte?"
âœ“ Cerca su siti ufficiali (MIUR, Indire)
âœ“ Numeri troppo precisi = red flag
```

**Come Difendersi dalle Allucinazioni:**

```
REGOLA D'ORO:
"Fidarsi Ã¨ bene, NON fidarsi Ã¨ meglio!"

âœ… CHECKLIST ANTI-ALLUCINAZIONE:

1. COMPILA SEMPRE IL CODICE
   [ ] gcc compila senza errori?
   [ ] Zero warning con -Wall -Wextra?

2. VERIFICA FUNZIONI/LIBRERIE
   [ ] Cerchi documentazione ufficiale
   [ ] Esiste su cppreference.com (C/C++)?
   [ ] Esiste su Arduino Library Manager?

3. TESTA L'OUTPUT
   [ ] Unit test passano?
   [ ] Edge cases gestiti?
   [ ] Valgrind pulito (no leak)?

4. CONTROLLA "FATTI"
   [ ] Numeri troppo specifici?
   [ ] Fonte citata verificabile?
   [ ] Cerca su Google per conferma

5. USA STRUMENTI
   [ ] Static analysis (cppcheck)
   [ ] Linter
   [ ] Compiler warning TUTTI abilitati
```

**Segnali di Allarme (Red Flags):**

```
ğŸš© RED FLAGS - Probabile Allucinazione:

âš ï¸ "Secondo recenti studi..."
   â†’ Senza citare fonte = inventato

âš ï¸ Funzione che non hai mai visto
   â†’ Cerca SEMPRE se non conosci

âš ï¸ Numeri troppo specifici
   â†’ "45.732 studenti" vs "~46.000"

âš ï¸ "La libreria XYZ fornisce..."
   â†’ Verifica che esista!

âš ï¸ Codice compila ma non funziona
   â†’ Logica inventata, sintassi ok

âš ï¸ "Questa funzione Ã¨ stata introdotta in C99"
   â†’ Verifica su standard ufficiale
```

### 4.2 Bias nei Dati di Training

**Cos'Ã¨ il Bias?**

> **Bias**: Pregiudizi o distorsioni nei dati di training che si riflettono nelle risposte del modello.

**Esempi di Bias in Programmazione:**

#### **1. Bias Linguistico**

```
PROBLEMA:
L'IA Ã¨ molto piÃ¹ brava in INGLESE che italiano

ESEMPIO:
Prompt INGLESE:
"Implement binary search in C"
â†’ Output: Perfetto, ottimizzato, 95% corretto

Prompt ITALIANO:
"Implementa ricerca binaria in C"
â†’ Output: Funziona ma meno ottimizzato, 80% corretto

SOLUZIONE:
âœ“ Usa prompts in inglese per codice
âœ“ Commenti possono essere in italiano
âœ“ Nomi funzioni in inglese (best practice comunque)
```

#### **2. Bias Platform/Hardware**

```
PROBLEMA:
PiÃ¹ esempi per hardware popolari

BIAS EVIDENTI:
- Arduino Uno >> Arduino Mega >> STM32 >> PIC
- Raspberry Pi >> ESP32 >> Arduino
- x86/Linux >> ARM/Windows >> RISC-V

ESEMPIO:
"Configura I2C su Arduino"
â†’ Esempi per Uno (Wire.h)

"Configura I2C su PIC18F"
â†’ Risposta generica, meno precisa

SOLUZIONE:
âœ“ Specifica ESATTAMENTE il modello hardware
âœ“ Fornisci datasheet se possibile
âœ“ Chiedi alternative se primo tentativo vago
```

#### **3. Bias Temporale**

```
PROBLEMA:
Preferisce soluzioni vecchie/deprecate

ESEMPIO:
Prompt: "Temporizza Arduino"

Output potenziale:
delay(1000);  // âŒ Vecchio stile, bloccante

Invece di:
unsigned long previousMillis = 0;
if (millis() - previousMillis >= 1000) {
    // âœ… Moderno, non-bloccante
}

SOLUZIONE:
âœ“ Specifica anno/versione target
âœ“ Chiedi esplicitamente "metodo moderno 2025"
âœ“ Menziona "non-blocking" se rilevante
```

**Mitigare i Bias:**

```
PROMPT DESIGN ANTI-BIAS:

âŒ VAGO:
"Scrivi programma Arduino sensore"

âœ… SPECIFICO:
"Scrivi sketch Arduino Uno R4 (2024) con sensore
 DHT22, usando libreria DHT sensor library v1.4.6,
 pattern millis() non-bloccante moderno"

ELEMENTI CHIAVE:
âœ“ Hardware esatto con anno/revisione
âœ“ Versione libreria
âœ“ Anno/standard ("moderno 2025", "C99 standard")
âœ“ Best practices esplicite
```

### 4.3 Sicurezza e Privacy

**âš ï¸ REGOLA FONDAMENTALE:**

> **MAI inserire dati sensibili in LLM!**

**PerchÃ©?**

Quando scrivi qualcosa a ChatGPT/Claude:
1. Viene salvato nei loro server
2. Potrebbe essere usato per training futuro
3. Potrebbe essere visto da revisori umani (quality check)
4. Se c'Ã¨ breach, potrebbe trapelare

**âŒ NON INSERIRE MAI:**

```
ASSOLUTAMENTE VIETATO:

âŒ Password (anche vecchie!)
âŒ API keys / Token autenticazione
âŒ Dati personali:
   - Numeri telefono
   - Indirizzi email/casa
   - Codici fiscali
   - Carte credito (ovvio!)

âŒ Codice proprietario aziendale
   - Segreti commerciali
   - Algoritmi protetti
   - Configurazioni interne

âŒ Informazioni riservate ITS/scuola
   - Voti altri studenti
   - Dati sensibili progetti
```

**âœ… SAFE PRACTICES:**

```
COME USARE IN SICUREZZA:

âœ… GENERALIZZA il problema
Invece di:
  "Debug questo codice del server aziendale SuperSecretCorp..."

Usa:
  "Debug questo pattern di server web generico..."

âœ… USA DATI MOCK/ESEMPIO
Invece di:
  users = ["mario.rossi@email.com", "giuseppe.verdi@email.com"]

Usa:
  users = ["user1@example.com", "user2@example.com"]

âœ… RIMUOVI INFO IDENTIFICATIVE
Codice vero:
  #define SERVER_IP "192.168.1.100"
  #define API_KEY "sk_live_51H3..."

Codice per IA:
  #define SERVER_IP "XXX.XXX.XXX.XXX"
  #define API_KEY "YOUR_API_KEY_HERE"

âœ… USA VARIABILI PLACEHOLDER
Invece di nomi reali, usa:
  COMPANY_NAME, PROJECT_X, SECRET_KEY, etc.
```

**Esempio Pratico - Richiesta Sicura:**

```
âŒ NON SICURO:

"Debug questo codice del nostro sistema di allarme
presso cliente ACME Corp, IP 10.50.23.15,
password admin: Acme2024!
[codice con logica proprietaria]"

âœ… SICURO:

"Debug questo pattern per sistema embedded di
allarme generico. Hardware: Arduino Mega.
Problema: Timeout su connessione server.

[codice con IP/password rimossi, logica sanitizzata]
```

**Tool/Setting Privacy:**

```
OPZIONI PRIVACY (varia per provider):

ChatGPT:
Settings â†’ Data Controls
â–¡ Disable "Improve model for everyone"
  â†’ I tuoi chat NON usati per training

Claude:
Settings â†’ Privacy
â–¡ Conversations private by default

Copilot (GitHub):
Settings â†’ telemetry
â–¡ Disable se non vuoi condividere snippet
```

### 4.4 Linee Guida Uso Responsabile

**Principi Fondamentali:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  REGOLE D'ORO USO IA 2025              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                        â”‚
â”‚  1. IA = ASSISTENTE, non SOSTITUTO    â”‚
â”‚     Tu sei il programmatore,           â”‚
â”‚     IA Ã¨ il tuo aiutante junior        â”‚
â”‚                                        â”‚
â”‚  2. VERIFICA SEMPRE output critici     â”‚
â”‚     Test, compila, valida              â”‚
â”‚                                        â”‚
â”‚  3. COMPRENDI il codice generato       â”‚
â”‚     Se non capisci, non usare!         â”‚
â”‚     Chiedi spiegazione all'IA stessa   â”‚
â”‚                                        â”‚
â”‚  4. MANTIENI competenze tecniche       â”‚
â”‚     Non diventare dipendente           â”‚
â”‚     Studia i fondamentali              â”‚
â”‚                                        â”‚
â”‚  5. USA ETICA in contesti accademici   â”‚
â”‚     Chiedi al prof se Ã¨ permesso       â”‚
â”‚     Cita uso IA se richiesto           â”‚
â”‚                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**âœ… Usi Corretti:**

```
DO - Esempi Concreti:

âœ“ LEARNING:
  "Spiega come funziona malloc() in C"
  â†’ Ottimo per capire concetti!

âœ“ DEBUGGING:
  "PerchÃ© questo codice ha memory leak?"
  [codice di un tuo progetto personale]
  â†’ Aiuto nel trovare bug

âœ“ BOILERPLATE:
  "Genera setup base Arduino con serial + LED"
  â†’ Accelera tasks ripetitivi

âœ“ REFACTORING:
  "Come posso migliorare questo codice?"
  â†’ Impari best practices

âœ“ IDEAZIONE:
  "Suggerisci architettura per sistema IoT"
  â†’ Brainstorming tecnico

âœ“ DOCUMENTAZIONE:
  "Genera README per questo progetto"
  â†’ Task tedioso automatizzato
```

**âŒ Usi Scorretti:**

```
DON'T - Esempi da EVITARE:

âŒ COPIA-INCOLLA CIECO:
   Prompt: "Fai esercizio 5 del compito"
   â†’ Copi senza capire
   â†’ Non impari niente
   â†’ Problematico eticamente

âŒ ESAMI SENZA PERMESSO:
   Usare IA durante test/esame
   â†’ Se non esplicitamente permesso = CHEATING

âŒ DIPENDENZA TOTALE:
   Non sai piÃ¹ fare niente senza IA
   â†’ Perdi competenze base
   â†’ Problema in colloqui/emergenze

âŒ CODICE PRODUCTION SENZA REVIEW:
   Deploy diretto codice IA
   â†’ Bug/vulnerabilitÃ 
   â†’ Irresponsabile

âŒ IGNORA WARNING:
   IA genera codice, compili con -Wall
   â†’ 10 warning
   â†’ Li ignori "tanto funziona"
   â†’ âŒ PESSIMA PRATICA

âŒ SOSTITUISCI RAGIONAMENTO:
   "IA non posso pensare per te"
   â†’ Diventi passivo
   â†’ Non sviluppi problem solving
```

**Uso Etico in Contesto Accademico:**

```
GUIDELINES ITS/UNIVERSITÃ€:

SEMPRE PERMESSO:
âœ“ Studiare concetti con IA
âœ“ Chiedere spiegazioni teoria
âœ“ Praticare con esercizi extra generati da IA
âœ“ Debug progetti personali

PERMESSO SE ESPLICITAMENTE AUTORIZZATO:
âš ï¸ Usare IA per compiti/progetti
âš ï¸ Generare parti di codice per assignment
âš ï¸ Refactoring progetti graded

MAI PERMESSO (salvo eccezioni):
âŒ Esami/test scritti
âŒ Valutazioni individuali
âŒ Certificazioni

REGOLA:
"Se in dubbio, CHIEDI al docente!"

CITAZIONE:
Se usi IA per progetto e permesso:
"""
Parti di questo codice sono state generate con
assistenza di [ChatGPT/Claude/Copilot], poi
validate e testate dallo studente.
Specificamente: [funzione X, algoritmo Y]
"""
```

**Auto-Valutazione Uso Responsabile:**

```
DOMANDE DA FARTI:

â–¡ Capisco al 100% il codice generato?
  NO â†’ Studia finchÃ© capisci

â–¡ Ho testato tutti i casi edge?
  NO â†’ Scrivi piÃ¹ test

â–¡ So spiegare ogni riga a un collega?
  NO â†’ Non sei pronto a usarlo

â–¡ Sarei in grado di riscriverlo da zero?
  NO â†’ Stai imparando o solo copiando?

â–¡ Ãˆ permesso usare IA per questo task?
  DUBBIO â†’ Chiedi al docente/responsabile

â–¡ Ho verificato non ci sono vulnerabilitÃ ?
  NO â†’ Code review + static analysis

Se rispondi NO a qualcuna:
â†’ Fermati e correggi prima di procedere!
```

